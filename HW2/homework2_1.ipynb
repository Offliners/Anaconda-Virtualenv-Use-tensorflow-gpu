{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxPVsK9NxN3DCekR9Dkyl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Offliners/Anaconda-Virtualenv-Use-tensorflow-gpu/blob/master/HW2/homework2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYxMSxsmAYm"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**\r\n",
        "\r\n",
        "The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\r\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\r\n",
        "\r\n",
        "This homework is a multiclass classification task, we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\r\n",
        "\r\n",
        "## **Download Data**\r\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3\r\n",
        "\r\n",
        "timit_11/\r\n",
        "\r\n",
        "* train_11.npy: training data\r\n",
        "* train_label_11.npy: training label\r\n",
        "* test_11.npy: testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N98vZGvSl-Fq",
        "outputId": "f8e422d8-55a2-4fa7-aa47-3eba721f1c81"
      },
      "source": [
        "!gdown --id '1duKUYSwilRG6BF8cLz8L_LRGDE7EFLHG' --output data.zip\r\n",
        "!unzip data.zip\r\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1duKUYSwilRG6BF8cLz8L_LRGDE7EFLHG\n",
            "To: /content/data.zip\n",
            "376MB [00:01, 245MB/s]\n",
            "Archive:  data.zip\n",
            "replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: timit_11/timit_11/test_11.npy  \n",
            "  inflating: timit_11/timit_11/train_11.npy  \n",
            "  inflating: timit_11/timit_11/train_label_11.npy  \n",
            "data.zip  model.ckpt  sample_data  sampleSubmission.csv  timit_11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffxBMT3mU5g"
      },
      "source": [
        "# **Preparing Data**\r\n",
        "\r\n",
        "Load the training and testing data from the .npy file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTYp6bemeRk",
        "outputId": "b4d950a1-768a-415f-b04e-9c00c8bc8fe5"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "print('Loading data ...')\r\n",
        "\r\n",
        "data_root='./timit_11/timit_11/'\r\n",
        "train = np.load(data_root + 'train_11.npy')\r\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\r\n",
        "test = np.load(data_root + 'test_11.npy')\r\n",
        "\r\n",
        "print('Size of training data: {}'.format(train.shape))\r\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQ84yh8me6A"
      },
      "source": [
        "# **Create Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPvM4GoFmhzo"
      },
      "source": [
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "class TIMITDataset(Dataset):\r\n",
        "    def __init__(self, X, y=None):\r\n",
        "        self.data = torch.from_numpy(X).float()\r\n",
        "        if y is not None:\r\n",
        "            y = y.astype(np.int)\r\n",
        "            self.label = torch.LongTensor(y)\r\n",
        "        else:\r\n",
        "            self.label = None\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if self.label is not None:\r\n",
        "            return self.data[idx], self.label[idx]\r\n",
        "        else:\r\n",
        "            return self.data[idx]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmKia2rfmmk9",
        "outputId": "4d65181f-f525-4ea2-a31a-eff2a44c3fe6"
      },
      "source": [
        "VAL_RATIO = 0.2\r\n",
        "\r\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\r\n",
        "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\r\n",
        "print('Size of training set: {}'.format(train_x.shape))\r\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: (983945, 429)\n",
            "Size of validation set: (245987, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1fNcNamqKa"
      },
      "source": [
        "BATCH_SIZE = 512\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "train_set = TIMITDataset(train_x, train_y)\r\n",
        "val_set = TIMITDataset(val_x, val_y)\r\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\r\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kqycVinmj11"
      },
      "source": [
        "#### **notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later the data size is quite huge, so be aware of memory usage in colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7dGNUuGmtDD",
        "outputId": "59407e2d-c2ef-4666-aed8-fd4f94cd5368"
      },
      "source": [
        "import gc\r\n",
        "\r\n",
        "del train, train_label, train_x, train_y, val_x, val_y\r\n",
        "gc.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXFtiY94m6X-"
      },
      "source": [
        "# **Create Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfFT6XJ8nBCS"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "class Classifier(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Classifier, self).__init__()\r\n",
        "        self.layer1 = nn.Linear(429, 2048)\r\n",
        "        self.layer2 = nn.Linear(2048, 2048)\r\n",
        "        self.layer3 = nn.Linear(2048, 1024)\r\n",
        "        self.layer4 = nn.Linear(1024, 256)\r\n",
        "        self.layer5 = nn.Linear(256, 128)\r\n",
        "        self.out = nn.Linear(128, 39) \r\n",
        "        self.dp = nn.Dropout(0.5)\r\n",
        "        self.bn1 = nn.BatchNorm1d(2048)\r\n",
        "        self.bn2 = nn.BatchNorm1d(2048)\r\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\r\n",
        "        self.bn4 = nn.BatchNorm1d(256)\r\n",
        "        self.bn5 = nn.BatchNorm1d(128)\r\n",
        "\r\n",
        "        self.act_fn = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn3(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn4(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer5(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn5(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.out(x)\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GLq4t_knLUL"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBsChEconOOV",
        "outputId": "de70f5ea-7e6e-4480-9c9f-9e826cca500e"
      },
      "source": [
        "#check device\r\n",
        "def get_device():\r\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "# fix random seed\r\n",
        "def same_seeds(seed):\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        torch.cuda.manual_seed(seed)\r\n",
        "        torch.cuda.manual_seed_all(seed)  \r\n",
        "    np.random.seed(seed)  \r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "# fix random seed for reproducibility\r\n",
        "same_seeds(0)\r\n",
        "\r\n",
        "# get device \r\n",
        "device = get_device()\r\n",
        "print(f'DEVICE: {device}')\r\n",
        "\r\n",
        "# training parameters\r\n",
        "num_epoch = 100               # number of training epoch\r\n",
        "learning_rate = 1e-4         # learning rate\r\n",
        "l2 = 1e-3                    # L2 regularization\r\n",
        "\r\n",
        "# the path where checkpoint saved\r\n",
        "model_path = './model.ckpt'\r\n",
        "\r\n",
        "# create model, define a loss function, and optimizer\r\n",
        "model = Classifier().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss() \r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyjl3itJnWwL",
        "outputId": "0ec2cf9f-2b19-4737-dfe6-8bdbc63b370f"
      },
      "source": [
        "# start training\r\n",
        "\r\n",
        "best_acc = 0.0\r\n",
        "for epoch in range(num_epoch):\r\n",
        "    train_acc = 0.0\r\n",
        "    train_loss = 0.0\r\n",
        "    val_acc = 0.0\r\n",
        "    val_loss = 0.0\r\n",
        "\r\n",
        "    # training\r\n",
        "    model.train() # set the model to training mode\r\n",
        "    for i, data in enumerate(train_loader):\r\n",
        "        inputs, labels = data\r\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "        optimizer.zero_grad() \r\n",
        "        outputs = model(inputs) \r\n",
        "        batch_loss = criterion(outputs, labels)\r\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\r\n",
        "        batch_loss.backward() \r\n",
        "        optimizer.step() \r\n",
        "\r\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\r\n",
        "        train_loss += batch_loss.item()\r\n",
        "\r\n",
        "    # validation\r\n",
        "    if len(val_set) > 0:\r\n",
        "        model.eval() # set the model to evaluation mode\r\n",
        "        with torch.no_grad():\r\n",
        "            for i, data in enumerate(val_loader):\r\n",
        "                inputs, labels = data\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "                outputs = model(inputs)\r\n",
        "                batch_loss = criterion(outputs, labels) \r\n",
        "                _, val_pred = torch.max(outputs, 1) \r\n",
        "            \r\n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\r\n",
        "                val_loss += batch_loss.item()\r\n",
        "\r\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\r\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\r\n",
        "            ))\r\n",
        "\r\n",
        "            # if the model improves, save a checkpoint at this epoch\r\n",
        "            if val_acc > best_acc:\r\n",
        "                best_acc = val_acc\r\n",
        "                torch.save(model.state_dict(), model_path)\r\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\r\n",
        "    else:\r\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\r\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\r\n",
        "        ))\r\n",
        "\r\n",
        "# if not validating, save the last epoch\r\n",
        "if len(val_set) == 0:\r\n",
        "    torch.save(model.state_dict(), model_path)\r\n",
        "    print('saving model at last epoch')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/100] Train Acc: 0.452872 Loss: 1.970911 | Val Acc: 0.610496 loss: 1.301412\n",
            "saving model with acc 0.610\n",
            "[002/100] Train Acc: 0.568880 Loss: 1.479840 | Val Acc: 0.659177 loss: 1.124577\n",
            "saving model with acc 0.659\n",
            "[003/100] Train Acc: 0.604645 Loss: 1.347382 | Val Acc: 0.679881 loss: 1.046529\n",
            "saving model with acc 0.680\n",
            "[004/100] Train Acc: 0.624876 Loss: 1.270028 | Val Acc: 0.692427 loss: 1.003208\n",
            "saving model with acc 0.692\n",
            "[005/100] Train Acc: 0.639749 Loss: 1.217628 | Val Acc: 0.701561 loss: 0.966170\n",
            "saving model with acc 0.702\n",
            "[006/100] Train Acc: 0.651382 Loss: 1.174688 | Val Acc: 0.709855 loss: 0.935030\n",
            "saving model with acc 0.710\n",
            "[007/100] Train Acc: 0.660801 Loss: 1.142268 | Val Acc: 0.716062 loss: 0.912252\n",
            "saving model with acc 0.716\n",
            "[008/100] Train Acc: 0.667683 Loss: 1.115076 | Val Acc: 0.720119 loss: 0.896298\n",
            "saving model with acc 0.720\n",
            "[009/100] Train Acc: 0.673870 Loss: 1.092785 | Val Acc: 0.723270 loss: 0.882305\n",
            "saving model with acc 0.723\n",
            "[010/100] Train Acc: 0.678583 Loss: 1.075584 | Val Acc: 0.726152 loss: 0.871131\n",
            "saving model with acc 0.726\n",
            "[011/100] Train Acc: 0.683202 Loss: 1.060090 | Val Acc: 0.727831 loss: 0.868476\n",
            "saving model with acc 0.728\n",
            "[012/100] Train Acc: 0.685655 Loss: 1.048874 | Val Acc: 0.732848 loss: 0.851339\n",
            "saving model with acc 0.733\n",
            "[013/100] Train Acc: 0.689151 Loss: 1.036871 | Val Acc: 0.733819 loss: 0.847186\n",
            "saving model with acc 0.734\n",
            "[014/100] Train Acc: 0.690537 Loss: 1.028673 | Val Acc: 0.735157 loss: 0.839418\n",
            "saving model with acc 0.735\n",
            "[015/100] Train Acc: 0.693227 Loss: 1.018903 | Val Acc: 0.734998 loss: 0.838026\n",
            "[016/100] Train Acc: 0.694899 Loss: 1.012541 | Val Acc: 0.737084 loss: 0.831845\n",
            "saving model with acc 0.737\n",
            "[017/100] Train Acc: 0.696312 Loss: 1.006612 | Val Acc: 0.737206 loss: 0.829449\n",
            "saving model with acc 0.737\n",
            "[018/100] Train Acc: 0.698099 Loss: 1.000051 | Val Acc: 0.738072 loss: 0.827147\n",
            "saving model with acc 0.738\n",
            "[019/100] Train Acc: 0.698762 Loss: 0.995771 | Val Acc: 0.740909 loss: 0.818786\n",
            "saving model with acc 0.741\n",
            "[020/100] Train Acc: 0.700440 Loss: 0.990047 | Val Acc: 0.741116 loss: 0.816275\n",
            "saving model with acc 0.741\n",
            "[021/100] Train Acc: 0.701238 Loss: 0.986063 | Val Acc: 0.740763 loss: 0.817973\n",
            "[022/100] Train Acc: 0.702358 Loss: 0.983828 | Val Acc: 0.741336 loss: 0.815285\n",
            "saving model with acc 0.741\n",
            "[023/100] Train Acc: 0.703600 Loss: 0.978856 | Val Acc: 0.742035 loss: 0.812874\n",
            "saving model with acc 0.742\n",
            "[024/100] Train Acc: 0.704670 Loss: 0.974300 | Val Acc: 0.742820 loss: 0.807905\n",
            "saving model with acc 0.743\n",
            "[025/100] Train Acc: 0.705425 Loss: 0.971106 | Val Acc: 0.742901 loss: 0.807253\n",
            "saving model with acc 0.743\n",
            "[026/100] Train Acc: 0.706306 Loss: 0.968954 | Val Acc: 0.742450 loss: 0.810089\n",
            "[027/100] Train Acc: 0.707218 Loss: 0.965935 | Val Acc: 0.743568 loss: 0.804223\n",
            "saving model with acc 0.744\n",
            "[028/100] Train Acc: 0.707444 Loss: 0.962927 | Val Acc: 0.744592 loss: 0.802050\n",
            "saving model with acc 0.745\n",
            "[029/100] Train Acc: 0.708574 Loss: 0.960644 | Val Acc: 0.744966 loss: 0.801037\n",
            "saving model with acc 0.745\n",
            "[030/100] Train Acc: 0.708834 Loss: 0.959219 | Val Acc: 0.744999 loss: 0.800128\n",
            "saving model with acc 0.745\n",
            "[031/100] Train Acc: 0.708970 Loss: 0.957165 | Val Acc: 0.745905 loss: 0.797210\n",
            "saving model with acc 0.746\n",
            "[032/100] Train Acc: 0.710482 Loss: 0.954014 | Val Acc: 0.745755 loss: 0.798018\n",
            "[033/100] Train Acc: 0.710863 Loss: 0.951185 | Val Acc: 0.746487 loss: 0.794697\n",
            "saving model with acc 0.746\n",
            "[034/100] Train Acc: 0.710106 Loss: 0.951011 | Val Acc: 0.746958 loss: 0.794696\n",
            "saving model with acc 0.747\n",
            "[035/100] Train Acc: 0.711106 Loss: 0.947245 | Val Acc: 0.747263 loss: 0.792140\n",
            "saving model with acc 0.747\n",
            "[036/100] Train Acc: 0.711574 Loss: 0.947778 | Val Acc: 0.746816 loss: 0.793978\n",
            "[037/100] Train Acc: 0.712233 Loss: 0.945797 | Val Acc: 0.748056 loss: 0.790445\n",
            "saving model with acc 0.748\n",
            "[038/100] Train Acc: 0.712013 Loss: 0.945256 | Val Acc: 0.748084 loss: 0.790069\n",
            "saving model with acc 0.748\n",
            "[039/100] Train Acc: 0.712881 Loss: 0.942428 | Val Acc: 0.747568 loss: 0.792771\n",
            "[040/100] Train Acc: 0.713426 Loss: 0.940868 | Val Acc: 0.749149 loss: 0.786874\n",
            "saving model with acc 0.749\n",
            "[041/100] Train Acc: 0.714094 Loss: 0.938566 | Val Acc: 0.747442 loss: 0.789955\n",
            "[042/100] Train Acc: 0.714489 Loss: 0.938157 | Val Acc: 0.747621 loss: 0.790935\n",
            "[043/100] Train Acc: 0.714617 Loss: 0.937061 | Val Acc: 0.747084 loss: 0.790586\n",
            "[044/100] Train Acc: 0.715074 Loss: 0.935147 | Val Acc: 0.749812 loss: 0.788157\n",
            "saving model with acc 0.750\n",
            "[045/100] Train Acc: 0.716021 Loss: 0.932865 | Val Acc: 0.746881 loss: 0.792001\n",
            "[046/100] Train Acc: 0.715723 Loss: 0.932110 | Val Acc: 0.749344 loss: 0.787179\n",
            "[047/100] Train Acc: 0.715723 Loss: 0.931513 | Val Acc: 0.749897 loss: 0.785308\n",
            "saving model with acc 0.750\n",
            "[048/100] Train Acc: 0.715907 Loss: 0.930552 | Val Acc: 0.750271 loss: 0.782496\n",
            "saving model with acc 0.750\n",
            "[049/100] Train Acc: 0.715990 Loss: 0.929631 | Val Acc: 0.749747 loss: 0.785591\n",
            "[050/100] Train Acc: 0.717135 Loss: 0.929093 | Val Acc: 0.749080 loss: 0.784661\n",
            "[051/100] Train Acc: 0.716407 Loss: 0.928165 | Val Acc: 0.749954 loss: 0.784321\n",
            "[052/100] Train Acc: 0.717196 Loss: 0.926476 | Val Acc: 0.749991 loss: 0.784325\n",
            "[053/100] Train Acc: 0.717085 Loss: 0.926674 | Val Acc: 0.749653 loss: 0.782271\n",
            "[054/100] Train Acc: 0.717949 Loss: 0.924558 | Val Acc: 0.750027 loss: 0.780438\n",
            "[055/100] Train Acc: 0.717701 Loss: 0.924673 | Val Acc: 0.748934 loss: 0.787292\n",
            "[056/100] Train Acc: 0.717551 Loss: 0.923492 | Val Acc: 0.751117 loss: 0.782248\n",
            "saving model with acc 0.751\n",
            "[057/100] Train Acc: 0.719032 Loss: 0.922770 | Val Acc: 0.751088 loss: 0.778264\n",
            "[058/100] Train Acc: 0.718031 Loss: 0.922565 | Val Acc: 0.749865 loss: 0.782376\n",
            "[059/100] Train Acc: 0.718174 Loss: 0.922348 | Val Acc: 0.750706 loss: 0.780206\n",
            "[060/100] Train Acc: 0.719217 Loss: 0.920258 | Val Acc: 0.752125 loss: 0.778324\n",
            "saving model with acc 0.752\n",
            "[061/100] Train Acc: 0.718862 Loss: 0.920236 | Val Acc: 0.750532 loss: 0.780132\n",
            "[062/100] Train Acc: 0.719206 Loss: 0.919567 | Val Acc: 0.750479 loss: 0.780572\n",
            "[063/100] Train Acc: 0.719925 Loss: 0.917678 | Val Acc: 0.750023 loss: 0.783520\n",
            "[064/100] Train Acc: 0.719875 Loss: 0.917748 | Val Acc: 0.751902 loss: 0.777182\n",
            "[065/100] Train Acc: 0.719292 Loss: 0.918480 | Val Acc: 0.751381 loss: 0.775292\n",
            "[066/100] Train Acc: 0.719902 Loss: 0.917519 | Val Acc: 0.750434 loss: 0.779686\n",
            "[067/100] Train Acc: 0.719456 Loss: 0.918081 | Val Acc: 0.751341 loss: 0.775930\n",
            "[068/100] Train Acc: 0.720028 Loss: 0.916384 | Val Acc: 0.752617 loss: 0.775488\n",
            "saving model with acc 0.753\n",
            "[069/100] Train Acc: 0.719885 Loss: 0.915834 | Val Acc: 0.751686 loss: 0.776660\n",
            "[070/100] Train Acc: 0.720338 Loss: 0.914871 | Val Acc: 0.750889 loss: 0.781936\n",
            "[071/100] Train Acc: 0.720065 Loss: 0.916244 | Val Acc: 0.751312 loss: 0.777545\n",
            "[072/100] Train Acc: 0.720511 Loss: 0.915395 | Val Acc: 0.752276 loss: 0.777663\n",
            "[073/100] Train Acc: 0.720783 Loss: 0.914799 | Val Acc: 0.751336 loss: 0.778197\n",
            "[074/100] Train Acc: 0.720145 Loss: 0.914637 | Val Acc: 0.751845 loss: 0.778157\n",
            "[075/100] Train Acc: 0.720552 Loss: 0.914583 | Val Acc: 0.752857 loss: 0.771991\n",
            "saving model with acc 0.753\n",
            "[076/100] Train Acc: 0.721024 Loss: 0.913448 | Val Acc: 0.750995 loss: 0.777183\n",
            "[077/100] Train Acc: 0.720158 Loss: 0.914181 | Val Acc: 0.750975 loss: 0.779932\n",
            "[078/100] Train Acc: 0.720112 Loss: 0.913927 | Val Acc: 0.750922 loss: 0.779042\n",
            "[079/100] Train Acc: 0.720786 Loss: 0.913571 | Val Acc: 0.750637 loss: 0.775851\n",
            "[080/100] Train Acc: 0.721341 Loss: 0.912453 | Val Acc: 0.753133 loss: 0.771484\n",
            "saving model with acc 0.753\n",
            "[081/100] Train Acc: 0.721155 Loss: 0.911969 | Val Acc: 0.751918 loss: 0.773844\n",
            "[082/100] Train Acc: 0.720966 Loss: 0.912619 | Val Acc: 0.750914 loss: 0.778265\n",
            "[083/100] Train Acc: 0.721315 Loss: 0.910227 | Val Acc: 0.752536 loss: 0.774391\n",
            "[084/100] Train Acc: 0.721589 Loss: 0.910825 | Val Acc: 0.752426 loss: 0.773501\n",
            "[085/100] Train Acc: 0.721456 Loss: 0.910752 | Val Acc: 0.751946 loss: 0.775009\n",
            "[086/100] Train Acc: 0.721220 Loss: 0.911138 | Val Acc: 0.752812 loss: 0.772643\n",
            "[087/100] Train Acc: 0.721789 Loss: 0.908618 | Val Acc: 0.752926 loss: 0.773207\n",
            "[088/100] Train Acc: 0.721753 Loss: 0.909835 | Val Acc: 0.751365 loss: 0.775701\n",
            "[089/100] Train Acc: 0.721769 Loss: 0.910334 | Val Acc: 0.752259 loss: 0.774842\n",
            "[090/100] Train Acc: 0.721493 Loss: 0.909614 | Val Acc: 0.752686 loss: 0.772327\n",
            "[091/100] Train Acc: 0.722028 Loss: 0.907682 | Val Acc: 0.752227 loss: 0.773673\n",
            "[092/100] Train Acc: 0.721666 Loss: 0.908529 | Val Acc: 0.752723 loss: 0.773977\n",
            "[093/100] Train Acc: 0.721919 Loss: 0.907893 | Val Acc: 0.751727 loss: 0.776393\n",
            "[094/100] Train Acc: 0.722025 Loss: 0.907928 | Val Acc: 0.752938 loss: 0.773024\n",
            "[095/100] Train Acc: 0.721980 Loss: 0.907421 | Val Acc: 0.752995 loss: 0.773976\n",
            "[096/100] Train Acc: 0.722219 Loss: 0.907629 | Val Acc: 0.752251 loss: 0.775552\n",
            "[097/100] Train Acc: 0.722097 Loss: 0.908197 | Val Acc: 0.752263 loss: 0.774124\n",
            "[098/100] Train Acc: 0.723187 Loss: 0.906298 | Val Acc: 0.752918 loss: 0.772681\n",
            "[099/100] Train Acc: 0.722453 Loss: 0.906393 | Val Acc: 0.753129 loss: 0.774529\n",
            "[100/100] Train Acc: 0.722840 Loss: 0.905442 | Val Acc: 0.752837 loss: 0.770833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uTr80Panaq8"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiBILuUEncLl",
        "outputId": "88f82921-801a-4dee-d651-e891e42e5b77"
      },
      "source": [
        "# create testing dataset\r\n",
        "test_set = TIMITDataset(test, None)\r\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\r\n",
        "\r\n",
        "# create model and load weights from checkpoint\r\n",
        "model = Classifier().to(device)\r\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP_tUJeLnd94"
      },
      "source": [
        "predict = []\r\n",
        "model.eval() # set the model to evaluation mode\r\n",
        "with torch.no_grad():\r\n",
        "    for i, data in enumerate(test_loader):\r\n",
        "        inputs = data\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        outputs = model(inputs)\r\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\r\n",
        "\r\n",
        "        for y in test_pred.cpu().numpy():\r\n",
        "            predict.append(y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIjAsNTnhgs"
      },
      "source": [
        "# **Write prediction to a CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athJ5R7BnlN5",
        "outputId": "557fe346-4b94-4afe-d3e4-ff2c758f3a7b"
      },
      "source": [
        "with open('prediction.csv', 'w') as f:\r\n",
        "    f.write('Id,Class\\n')\r\n",
        "    for i, y in enumerate(predict):\r\n",
        "        f.write('{},{}\\n'.format(i, y))\r\n",
        "\r\n",
        "print('Saving results to prediction.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to prediction.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV5cHjHLos62"
      },
      "source": [
        "# **Reference**\r\n",
        "\r\n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb)"
      ]
    }
  ]
}